{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 데이터 수집","metadata":{"id":"oZSSk70xIGeR"}},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"eu140OB-r_l4","execution":{"iopub.status.busy":"2024-04-24T00:38:27.850510Z","iopub.execute_input":"2024-04-24T00:38:27.850943Z","iopub.status.idle":"2024-04-24T00:38:29.263794Z","shell.execute_reply.started":"2024-04-24T00:38:27.850908Z","shell.execute_reply":"2024-04-24T00:38:29.262336Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# wget로 추후 변경\ntrain_df = pd.read_csv('https://raw.githubusercontent.com/kangmg/Abalone_age_prediction/main/dataset/train.csv', index_col='id')\ntest_df = pd.read_csv('https://raw.githubusercontent.com/kangmg/Abalone_age_prediction/main/dataset/test.csv', index_col=\"id\")\nsample_df = pd.read_csv('https://raw.githubusercontent.com/kangmg/Abalone_age_prediction/main/dataset/sample_submission.csv')\noriginal_df = pd.read_csv('https://raw.githubusercontent.com/kangmg/Abalone_age_prediction/main/dataset/Original.csv', index_col='id')","metadata":{"id":"q4Ti5M5QsKLA","execution":{"iopub.status.busy":"2024-04-24T00:49:15.410211Z","iopub.execute_input":"2024-04-24T00:49:15.410674Z","iopub.status.idle":"2024-04-24T00:49:16.039018Z","shell.execute_reply.started":"2024-04-24T00:49:15.410617Z","shell.execute_reply":"2024-04-24T00:49:16.037931Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# train_df랑 original_df 피처명 다름 ->train_df로 고정\noriginal_df.columns = ['Sex','Length','Diameter','Height','Whole weight','Whole weight.1','Whole weight.2','Shell weight','Rings']","metadata":{"id":"p9rD21c18Lxy","execution":{"iopub.status.busy":"2024-04-24T00:49:21.362141Z","iopub.execute_input":"2024-04-24T00:49:21.362830Z","iopub.status.idle":"2024-04-24T00:49:21.368068Z","shell.execute_reply.started":"2024-04-24T00:49:21.362796Z","shell.execute_reply":"2024-04-24T00:49:21.366738Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# train_df와 original_df를 concat을 활용하여 합치기\ndf_train = pd.concat([train_df, original_df], ignore_index=True)\n\n# 결과 확인\ndf_train","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"QvZ9rAJo9CJ1","outputId":"3602f90d-2170-45e0-fa19-c8e4b12f3788","execution":{"iopub.status.busy":"2024-04-24T00:49:21.987155Z","iopub.execute_input":"2024-04-24T00:49:21.987573Z","iopub.status.idle":"2024-04-24T00:49:22.014679Z","shell.execute_reply.started":"2024-04-24T00:49:21.987540Z","shell.execute_reply":"2024-04-24T00:49:22.013239Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"      Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n0       F   0.550     0.430   0.150        0.7715          0.3285   \n1       F   0.630     0.490   0.145        1.1300          0.4580   \n2       I   0.160     0.110   0.025        0.0210          0.0055   \n3       M   0.595     0.475   0.150        0.9145          0.3755   \n4       I   0.555     0.425   0.130        0.7820          0.3695   \n...    ..     ...       ...     ...           ...             ...   \n94787   F   0.565     0.450   0.165        0.8870          0.3700   \n94788   M   0.590     0.440   0.135        0.9660          0.4390   \n94789   M   0.600     0.475   0.205        1.1760          0.5255   \n94790   F   0.625     0.485   0.150        1.0945          0.5310   \n94791   M   0.710     0.555   0.195        1.9485          0.9455   \n\n       Whole weight.2  Shell weight  Rings  \n0              0.1465        0.2400     11  \n1              0.2765        0.3200     11  \n2              0.0030        0.0050      6  \n3              0.2055        0.2500     10  \n4              0.1600        0.1975      9  \n...               ...           ...    ...  \n94787          0.2390        0.2490     11  \n94788          0.2145        0.2605     10  \n94789          0.2875        0.3080      9  \n94790          0.2610        0.2960     10  \n94791          0.3765        0.4950     12  \n\n[94792 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Whole weight.1</th>\n      <th>Whole weight.2</th>\n      <th>Shell weight</th>\n      <th>Rings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>F</td>\n      <td>0.550</td>\n      <td>0.430</td>\n      <td>0.150</td>\n      <td>0.7715</td>\n      <td>0.3285</td>\n      <td>0.1465</td>\n      <td>0.2400</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>0.630</td>\n      <td>0.490</td>\n      <td>0.145</td>\n      <td>1.1300</td>\n      <td>0.4580</td>\n      <td>0.2765</td>\n      <td>0.3200</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I</td>\n      <td>0.160</td>\n      <td>0.110</td>\n      <td>0.025</td>\n      <td>0.0210</td>\n      <td>0.0055</td>\n      <td>0.0030</td>\n      <td>0.0050</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>0.595</td>\n      <td>0.475</td>\n      <td>0.150</td>\n      <td>0.9145</td>\n      <td>0.3755</td>\n      <td>0.2055</td>\n      <td>0.2500</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>0.555</td>\n      <td>0.425</td>\n      <td>0.130</td>\n      <td>0.7820</td>\n      <td>0.3695</td>\n      <td>0.1600</td>\n      <td>0.1975</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94787</th>\n      <td>F</td>\n      <td>0.565</td>\n      <td>0.450</td>\n      <td>0.165</td>\n      <td>0.8870</td>\n      <td>0.3700</td>\n      <td>0.2390</td>\n      <td>0.2490</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>94788</th>\n      <td>M</td>\n      <td>0.590</td>\n      <td>0.440</td>\n      <td>0.135</td>\n      <td>0.9660</td>\n      <td>0.4390</td>\n      <td>0.2145</td>\n      <td>0.2605</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>94789</th>\n      <td>M</td>\n      <td>0.600</td>\n      <td>0.475</td>\n      <td>0.205</td>\n      <td>1.1760</td>\n      <td>0.5255</td>\n      <td>0.2875</td>\n      <td>0.3080</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>94790</th>\n      <td>F</td>\n      <td>0.625</td>\n      <td>0.485</td>\n      <td>0.150</td>\n      <td>1.0945</td>\n      <td>0.5310</td>\n      <td>0.2610</td>\n      <td>0.2960</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>94791</th>\n      <td>M</td>\n      <td>0.710</td>\n      <td>0.555</td>\n      <td>0.195</td>\n      <td>1.9485</td>\n      <td>0.9455</td>\n      <td>0.3765</td>\n      <td>0.4950</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n<p>94792 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df_train 요약 테이블(연속형)\ndef summary(df):\n    print(f'data shape: {df.shape}')\n    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n    summ['#missing'] = df.isnull().sum().values                 #각 열의 누락된 값의 개수\n    summ['%missing'] = df.isnull().sum().values / len(df)* 100  # 각 열의 누락된 값의 비율\n    summ['#unique'] = df.nunique()                              # 고유값 수\n    desc = pd.DataFrame(df.describe(include='all').transpose())\n    summ['min'] = desc['min'].values.round(3)                   # 최소값\n    summ['max'] = desc['max'].values.round(2)                   # 최대값\n    summ['first value'] = df.loc[0].values.round(2)\n    summ['second value'] = df.loc[1].values.round(2)\n    summ['third value'] = df.loc[2].values.round(2)\n\n    return summ\n\ndf_train_excluding_sex = df_train.drop(columns=['Sex'])         # 범주형 피처 제외\n\n\nsummary(df_train_excluding_sex)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"id":"ORSJ5MRz93z1","outputId":"62878cd0-5f9c-4cc9-eefd-91b643d7dafe","execution":{"iopub.status.busy":"2024-04-24T00:49:23.050213Z","iopub.execute_input":"2024-04-24T00:49:23.050641Z","iopub.status.idle":"2024-04-24T00:49:23.151392Z","shell.execute_reply.started":"2024-04-24T00:49:23.050606Z","shell.execute_reply":"2024-04-24T00:49:23.147982Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"data shape: (94792, 8)\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"               data type  #missing  %missing  #unique    min    max  \\\nLength           float64         0       0.0      157  0.075   0.82   \nDiameter         float64         0       0.0      126  0.055   0.65   \nHeight           float64         0       0.0       90  0.000   1.13   \nWhole weight     float64         0       0.0     3205  0.002   2.83   \nWhole weight.1   float64         0       0.0     1806  0.001   1.49   \nWhole weight.2   float64         0       0.0      983  0.000   0.76   \nShell weight     float64         0       0.0     1132  0.002   1.00   \nRings              int64         0       0.0       28  1.000  29.00   \n\n                first value  second value  third value  \nLength                 0.55          0.63         0.16  \nDiameter               0.43          0.49         0.11  \nHeight                 0.15          0.14         0.02  \nWhole weight           0.77          1.13         0.02  \nWhole weight.1         0.33          0.46         0.01  \nWhole weight.2         0.15          0.28         0.00  \nShell weight           0.24          0.32         0.00  \nRings                 11.00         11.00         6.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data type</th>\n      <th>#missing</th>\n      <th>%missing</th>\n      <th>#unique</th>\n      <th>min</th>\n      <th>max</th>\n      <th>first value</th>\n      <th>second value</th>\n      <th>third value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Length</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>157</td>\n      <td>0.075</td>\n      <td>0.82</td>\n      <td>0.55</td>\n      <td>0.63</td>\n      <td>0.16</td>\n    </tr>\n    <tr>\n      <th>Diameter</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>126</td>\n      <td>0.055</td>\n      <td>0.65</td>\n      <td>0.43</td>\n      <td>0.49</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>Height</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>90</td>\n      <td>0.000</td>\n      <td>1.13</td>\n      <td>0.15</td>\n      <td>0.14</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Whole weight</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3205</td>\n      <td>0.002</td>\n      <td>2.83</td>\n      <td>0.77</td>\n      <td>1.13</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Whole weight.1</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1806</td>\n      <td>0.001</td>\n      <td>1.49</td>\n      <td>0.33</td>\n      <td>0.46</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>Whole weight.2</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>983</td>\n      <td>0.000</td>\n      <td>0.76</td>\n      <td>0.15</td>\n      <td>0.28</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Shell weight</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1132</td>\n      <td>0.002</td>\n      <td>1.00</td>\n      <td>0.24</td>\n      <td>0.32</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Rings</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>28</td>\n      <td>1.000</td>\n      <td>29.00</td>\n      <td>11.00</td>\n      <td>11.00</td>\n      <td>6.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# EDA(일부분)","metadata":{"id":"LYjrg3O3IOHC"}},{"cell_type":"code","source":"temp = df_train.copy()","metadata":{"id":"TytAwTE8LD6f","execution":{"iopub.status.busy":"2024-04-24T00:49:26.712756Z","iopub.execute_input":"2024-04-24T00:49:26.713165Z","iopub.status.idle":"2024-04-24T00:49:26.720276Z","shell.execute_reply.started":"2024-04-24T00:49:26.713135Z","shell.execute_reply":"2024-04-24T00:49:26.719011Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# df_train에서만 BMI 시각화 체크 용도\ntemp['BMI'] = temp['Whole weight'] / (temp['Length'])**2\ntemp['estimated_grate'] = ( temp['Whole weight.1'] + temp['Whole weight.2'] ) / ( temp['Whole weight.1'] + temp['Whole weight.2'] + temp['Shell weight'] )\ntemp","metadata":{"id":"ziy2F8SHKzNF","execution":{"iopub.status.busy":"2024-04-24T00:49:26.847530Z","iopub.execute_input":"2024-04-24T00:49:26.847972Z","iopub.status.idle":"2024-04-24T00:49:26.881054Z","shell.execute_reply.started":"2024-04-24T00:49:26.847939Z","shell.execute_reply":"2024-04-24T00:49:26.880100Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"      Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n0       F   0.550     0.430   0.150        0.7715          0.3285   \n1       F   0.630     0.490   0.145        1.1300          0.4580   \n2       I   0.160     0.110   0.025        0.0210          0.0055   \n3       M   0.595     0.475   0.150        0.9145          0.3755   \n4       I   0.555     0.425   0.130        0.7820          0.3695   \n...    ..     ...       ...     ...           ...             ...   \n94787   F   0.565     0.450   0.165        0.8870          0.3700   \n94788   M   0.590     0.440   0.135        0.9660          0.4390   \n94789   M   0.600     0.475   0.205        1.1760          0.5255   \n94790   F   0.625     0.485   0.150        1.0945          0.5310   \n94791   M   0.710     0.555   0.195        1.9485          0.9455   \n\n       Whole weight.2  Shell weight  Rings       BMI  estimated_grate  \n0              0.1465        0.2400     11  2.550413         0.664336  \n1              0.2765        0.3200     11  2.847065         0.696539  \n2              0.0030        0.0050      6  0.820312         0.629630  \n3              0.2055        0.2500     10  2.583151         0.699158  \n4              0.1600        0.1975      9  2.538755         0.728336  \n...               ...           ...    ...       ...              ...  \n94787          0.2390        0.2490     11  2.778604         0.709790  \n94788          0.2145        0.2605     10  2.775065         0.714989  \n94789          0.2875        0.3080      9  3.266667         0.725245  \n94790          0.2610        0.2960     10  2.801920         0.727941  \n94791          0.3765        0.4950     12  3.865305         0.727573  \n\n[94792 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Whole weight.1</th>\n      <th>Whole weight.2</th>\n      <th>Shell weight</th>\n      <th>Rings</th>\n      <th>BMI</th>\n      <th>estimated_grate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>F</td>\n      <td>0.550</td>\n      <td>0.430</td>\n      <td>0.150</td>\n      <td>0.7715</td>\n      <td>0.3285</td>\n      <td>0.1465</td>\n      <td>0.2400</td>\n      <td>11</td>\n      <td>2.550413</td>\n      <td>0.664336</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>0.630</td>\n      <td>0.490</td>\n      <td>0.145</td>\n      <td>1.1300</td>\n      <td>0.4580</td>\n      <td>0.2765</td>\n      <td>0.3200</td>\n      <td>11</td>\n      <td>2.847065</td>\n      <td>0.696539</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I</td>\n      <td>0.160</td>\n      <td>0.110</td>\n      <td>0.025</td>\n      <td>0.0210</td>\n      <td>0.0055</td>\n      <td>0.0030</td>\n      <td>0.0050</td>\n      <td>6</td>\n      <td>0.820312</td>\n      <td>0.629630</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>0.595</td>\n      <td>0.475</td>\n      <td>0.150</td>\n      <td>0.9145</td>\n      <td>0.3755</td>\n      <td>0.2055</td>\n      <td>0.2500</td>\n      <td>10</td>\n      <td>2.583151</td>\n      <td>0.699158</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>0.555</td>\n      <td>0.425</td>\n      <td>0.130</td>\n      <td>0.7820</td>\n      <td>0.3695</td>\n      <td>0.1600</td>\n      <td>0.1975</td>\n      <td>9</td>\n      <td>2.538755</td>\n      <td>0.728336</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94787</th>\n      <td>F</td>\n      <td>0.565</td>\n      <td>0.450</td>\n      <td>0.165</td>\n      <td>0.8870</td>\n      <td>0.3700</td>\n      <td>0.2390</td>\n      <td>0.2490</td>\n      <td>11</td>\n      <td>2.778604</td>\n      <td>0.709790</td>\n    </tr>\n    <tr>\n      <th>94788</th>\n      <td>M</td>\n      <td>0.590</td>\n      <td>0.440</td>\n      <td>0.135</td>\n      <td>0.9660</td>\n      <td>0.4390</td>\n      <td>0.2145</td>\n      <td>0.2605</td>\n      <td>10</td>\n      <td>2.775065</td>\n      <td>0.714989</td>\n    </tr>\n    <tr>\n      <th>94789</th>\n      <td>M</td>\n      <td>0.600</td>\n      <td>0.475</td>\n      <td>0.205</td>\n      <td>1.1760</td>\n      <td>0.5255</td>\n      <td>0.2875</td>\n      <td>0.3080</td>\n      <td>9</td>\n      <td>3.266667</td>\n      <td>0.725245</td>\n    </tr>\n    <tr>\n      <th>94790</th>\n      <td>F</td>\n      <td>0.625</td>\n      <td>0.485</td>\n      <td>0.150</td>\n      <td>1.0945</td>\n      <td>0.5310</td>\n      <td>0.2610</td>\n      <td>0.2960</td>\n      <td>10</td>\n      <td>2.801920</td>\n      <td>0.727941</td>\n    </tr>\n    <tr>\n      <th>94791</th>\n      <td>M</td>\n      <td>0.710</td>\n      <td>0.555</td>\n      <td>0.195</td>\n      <td>1.9485</td>\n      <td>0.9455</td>\n      <td>0.3765</td>\n      <td>0.4950</td>\n      <td>12</td>\n      <td>3.865305</td>\n      <td>0.727573</td>\n    </tr>\n  </tbody>\n</table>\n<p>94792 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"- 이상치 제거 목표\n    - Height : 0.4 이상 이상치 처리 -> 제거\n    - Whole weight : 0.7 이상 이상치 처리 -> 제거\n    - BMI : 10 이상 이상치 처리 -> 제거","metadata":{"id":"J5jRzbHJLZ2q"}},{"cell_type":"markdown","source":"# 피처 엔지니어링","metadata":{"id":"EzqbGhD-IPKA"}},{"cell_type":"code","source":"# BMI 피처 추가 생성 -> 이유 : Whole weight를 더 세분화 가능할듯 싶어서?\n# 사람의 경우에도 연령대별로 BMI 분포가 다름. https://www.index.go.kr/unify/idx-info.do?idxCd=8021\ndf_train['BMI'] = df_train['Whole weight'] / (df_train['Length'])**2\ndf_train['estimated_grate'] = ( df_train['Whole weight.1'] + df_train['Whole weight.2'] ) / ( df_train['Whole weight.1'] + df_train['Whole weight.2'] + df_train['Shell weight'] )\n","metadata":{"id":"PomiAuinNHbH","execution":{"iopub.status.busy":"2024-04-24T00:49:32.926647Z","iopub.execute_input":"2024-04-24T00:49:32.928019Z","iopub.status.idle":"2024-04-24T00:49:32.939261Z","shell.execute_reply.started":"2024-04-24T00:49:32.927968Z","shell.execute_reply":"2024-04-24T00:49:32.938018Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"test_df['BMI'] = test_df['Whole weight'] / (test_df['Length'])**2\ntest_df['estimated_grate'] = ( test_df['Whole weight.1'] + test_df['Whole weight.2'] ) / ( test_df['Whole weight.1'] + test_df['Whole weight.2'] + test_df['Shell weight'] )\n","metadata":{"id":"DfncF8wqNHvT","execution":{"iopub.status.busy":"2024-04-24T00:49:33.064959Z","iopub.execute_input":"2024-04-24T00:49:33.065407Z","iopub.status.idle":"2024-04-24T00:49:33.076466Z","shell.execute_reply.started":"2024-04-24T00:49:33.065371Z","shell.execute_reply":"2024-04-24T00:49:33.075379Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# 이상치를 제거하는 함수 정의\ndef remove_outliers(df, column, threshold):\n    # 주어진 열(column)에서 이상치를 식별하여 제거\n    df_cleaned = df[df[column] < threshold]\n    return df_cleaned\n\n# 이상치 제거 적용\n# Height 컬럼의 이상치 제거\nthreshold_height = 0.4\ndf_cleaned = remove_outliers(df_train, 'Height', threshold_height)\n\n# Whole weight 컬럼의 이상치 제거\nthreshold_whole_weight_2 = 0.7\ndf_cleaned = remove_outliers(df_cleaned, 'Whole weight.2', threshold_whole_weight_2)\n\n# BMI 컬럼의 이상치 제거\nthreshold_bmi = 10\ndf_cleaned = remove_outliers(df_cleaned, 'BMI', threshold_bmi)\n\n# 결과 확인\nprint(\"이상치 제거 후 데이터 크기:\", df_cleaned.shape)\nprint(\"제거된 행의 수:\", df_train.shape[0] - df_cleaned.shape[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOgbi-hMMaTu","outputId":"c9e7f887-2cb9-4b01-8eec-741ccbc1ff59","execution":{"iopub.status.busy":"2024-04-24T00:49:35.484193Z","iopub.execute_input":"2024-04-24T00:49:35.484621Z","iopub.status.idle":"2024-04-24T00:49:35.518413Z","shell.execute_reply.started":"2024-04-24T00:49:35.484587Z","shell.execute_reply":"2024-04-24T00:49:35.517063Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"이상치 제거 후 데이터 크기: (94778, 11)\n제거된 행의 수: 14\n","output_type":"stream"}]},{"cell_type":"code","source":"# df_cleaned과 test_df를 concat을 활용하여 합치기\nall_data = pd.concat([df_cleaned, test_df], ignore_index=True)\n\n# 결과 확인\nall_data","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"7V1hP09IcK99","outputId":"50812aca-3d14-41b2-f800-547ac005050d","execution":{"iopub.status.busy":"2024-04-24T00:49:37.991145Z","iopub.execute_input":"2024-04-24T00:49:37.991543Z","iopub.status.idle":"2024-04-24T00:49:38.024639Z","shell.execute_reply.started":"2024-04-24T00:49:37.991513Z","shell.execute_reply":"2024-04-24T00:49:38.023238Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"       Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n0        F   0.550     0.430   0.150        0.7715          0.3285   \n1        F   0.630     0.490   0.145        1.1300          0.4580   \n2        I   0.160     0.110   0.025        0.0210          0.0055   \n3        M   0.595     0.475   0.150        0.9145          0.3755   \n4        I   0.555     0.425   0.130        0.7820          0.3695   \n...     ..     ...       ...     ...           ...             ...   \n155184   I   0.345     0.260   0.085        0.1775          0.0735   \n155185   F   0.525     0.410   0.145        0.8445          0.3885   \n155186   I   0.590     0.440   0.155        1.1220          0.3930   \n155187   F   0.660     0.525   0.190        1.4935          0.5885   \n155188   F   0.430     0.340   0.120        0.4150          0.1525   \n\n        Whole weight.2  Shell weight  Rings       BMI  estimated_grate  \n0               0.1465        0.2400   11.0  2.550413         0.664336  \n1               0.2765        0.3200   11.0  2.847065         0.696539  \n2               0.0030        0.0050    6.0  0.820312         0.629630  \n3               0.2055        0.2500   10.0  2.583151         0.699158  \n4               0.1600        0.1975    9.0  2.538755         0.728336  \n...                ...           ...    ...       ...              ...  \n155184          0.0265        0.0500    NaN  1.491283         0.666667  \n155185          0.1670        0.2050    NaN  3.063946         0.730440  \n155186          0.2000        0.2650    NaN  3.223212         0.691142  \n155187          0.3575        0.4350    NaN  3.428604         0.685011  \n155188          0.0910        0.0905    NaN  2.244456         0.729042  \n\n[155189 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Whole weight.1</th>\n      <th>Whole weight.2</th>\n      <th>Shell weight</th>\n      <th>Rings</th>\n      <th>BMI</th>\n      <th>estimated_grate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>F</td>\n      <td>0.550</td>\n      <td>0.430</td>\n      <td>0.150</td>\n      <td>0.7715</td>\n      <td>0.3285</td>\n      <td>0.1465</td>\n      <td>0.2400</td>\n      <td>11.0</td>\n      <td>2.550413</td>\n      <td>0.664336</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>0.630</td>\n      <td>0.490</td>\n      <td>0.145</td>\n      <td>1.1300</td>\n      <td>0.4580</td>\n      <td>0.2765</td>\n      <td>0.3200</td>\n      <td>11.0</td>\n      <td>2.847065</td>\n      <td>0.696539</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I</td>\n      <td>0.160</td>\n      <td>0.110</td>\n      <td>0.025</td>\n      <td>0.0210</td>\n      <td>0.0055</td>\n      <td>0.0030</td>\n      <td>0.0050</td>\n      <td>6.0</td>\n      <td>0.820312</td>\n      <td>0.629630</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>0.595</td>\n      <td>0.475</td>\n      <td>0.150</td>\n      <td>0.9145</td>\n      <td>0.3755</td>\n      <td>0.2055</td>\n      <td>0.2500</td>\n      <td>10.0</td>\n      <td>2.583151</td>\n      <td>0.699158</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>0.555</td>\n      <td>0.425</td>\n      <td>0.130</td>\n      <td>0.7820</td>\n      <td>0.3695</td>\n      <td>0.1600</td>\n      <td>0.1975</td>\n      <td>9.0</td>\n      <td>2.538755</td>\n      <td>0.728336</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>155184</th>\n      <td>I</td>\n      <td>0.345</td>\n      <td>0.260</td>\n      <td>0.085</td>\n      <td>0.1775</td>\n      <td>0.0735</td>\n      <td>0.0265</td>\n      <td>0.0500</td>\n      <td>NaN</td>\n      <td>1.491283</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>155185</th>\n      <td>F</td>\n      <td>0.525</td>\n      <td>0.410</td>\n      <td>0.145</td>\n      <td>0.8445</td>\n      <td>0.3885</td>\n      <td>0.1670</td>\n      <td>0.2050</td>\n      <td>NaN</td>\n      <td>3.063946</td>\n      <td>0.730440</td>\n    </tr>\n    <tr>\n      <th>155186</th>\n      <td>I</td>\n      <td>0.590</td>\n      <td>0.440</td>\n      <td>0.155</td>\n      <td>1.1220</td>\n      <td>0.3930</td>\n      <td>0.2000</td>\n      <td>0.2650</td>\n      <td>NaN</td>\n      <td>3.223212</td>\n      <td>0.691142</td>\n    </tr>\n    <tr>\n      <th>155187</th>\n      <td>F</td>\n      <td>0.660</td>\n      <td>0.525</td>\n      <td>0.190</td>\n      <td>1.4935</td>\n      <td>0.5885</td>\n      <td>0.3575</td>\n      <td>0.4350</td>\n      <td>NaN</td>\n      <td>3.428604</td>\n      <td>0.685011</td>\n    </tr>\n    <tr>\n      <th>155188</th>\n      <td>F</td>\n      <td>0.430</td>\n      <td>0.340</td>\n      <td>0.120</td>\n      <td>0.4150</td>\n      <td>0.1525</td>\n      <td>0.0910</td>\n      <td>0.0905</td>\n      <td>NaN</td>\n      <td>2.244456</td>\n      <td>0.729042</td>\n    </tr>\n  </tbody>\n</table>\n<p>155189 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 'Sex' 컬럼을 원-핫 인코딩하여 더미 변수 생성\ndata_encoded = pd.get_dummies(all_data, columns=['Sex'], dtype=int)","metadata":{"id":"mIw0e32AYGwW","execution":{"iopub.status.busy":"2024-04-24T00:49:40.593196Z","iopub.execute_input":"2024-04-24T00:49:40.593642Z","iopub.status.idle":"2024-04-24T00:49:40.652308Z","shell.execute_reply.started":"2024-04-24T00:49:40.593598Z","shell.execute_reply":"2024-04-24T00:49:40.650904Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"data_encoded.head(2)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"Ih_bWF72YXOB","outputId":"6d562e24-e426-4dfb-a15f-c1b72ffc3772","execution":{"iopub.status.busy":"2024-04-24T00:49:42.060274Z","iopub.execute_input":"2024-04-24T00:49:42.060710Z","iopub.status.idle":"2024-04-24T00:49:42.080592Z","shell.execute_reply.started":"2024-04-24T00:49:42.060679Z","shell.execute_reply":"2024-04-24T00:49:42.079293Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n0    0.55      0.43   0.150        0.7715          0.3285          0.1465   \n1    0.63      0.49   0.145        1.1300          0.4580          0.2765   \n\n   Shell weight  Rings       BMI  estimated_grate  Sex_F  Sex_I  Sex_M  \n0          0.24   11.0  2.550413         0.664336      1      0      0  \n1          0.32   11.0  2.847065         0.696539      1      0      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Whole weight.1</th>\n      <th>Whole weight.2</th>\n      <th>Shell weight</th>\n      <th>Rings</th>\n      <th>BMI</th>\n      <th>estimated_grate</th>\n      <th>Sex_F</th>\n      <th>Sex_I</th>\n      <th>Sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.55</td>\n      <td>0.43</td>\n      <td>0.150</td>\n      <td>0.7715</td>\n      <td>0.3285</td>\n      <td>0.1465</td>\n      <td>0.24</td>\n      <td>11.0</td>\n      <td>2.550413</td>\n      <td>0.664336</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.63</td>\n      <td>0.49</td>\n      <td>0.145</td>\n      <td>1.1300</td>\n      <td>0.4580</td>\n      <td>0.2765</td>\n      <td>0.32</td>\n      <td>11.0</td>\n      <td>2.847065</td>\n      <td>0.696539</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\n# Robustscaler 객체 생성\nscaler = RobustScaler()\n\n# A와 B 변수에 대해 표준화 수행\ndata_encoded[['Length','Diameter','Height','Whole weight',\n              'Whole weight.1','Whole weight.2','Shell weight','BMI', 'estimated_grate']] = scaler.fit_transform(data_encoded[['Length','Diameter','Height',\n                                                                                                      'Whole weight','Whole weight.1',\n                                                                                                      'Whole weight.2','Shell weight','BMI', 'estimated_grate']])","metadata":{"id":"ffwQYt0rYhPW","execution":{"iopub.status.busy":"2024-04-24T00:49:44.396634Z","iopub.execute_input":"2024-04-24T00:49:44.397074Z","iopub.status.idle":"2024-04-24T00:49:44.475868Z","shell.execute_reply.started":"2024-04-24T00:49:44.397042Z","shell.execute_reply":"2024-04-24T00:49:44.474577Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# 결과 확인\ndata_encoded","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"R0S-wpBNDDF4","outputId":"d2e721af-349c-4a34-9c5e-6d93e7542c15","execution":{"iopub.status.busy":"2024-04-24T00:49:44.939329Z","iopub.execute_input":"2024-04-24T00:49:44.939772Z","iopub.status.idle":"2024-04-24T00:49:44.967331Z","shell.execute_reply.started":"2024-04-24T00:49:44.939714Z","shell.execute_reply":"2024-04-24T00:49:44.965975Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"          Length  Diameter  Height  Whole weight  Whole weight.1  \\\n0       0.032258      0.04     0.2     -0.042945       -0.005245   \n1       0.548387      0.52     0.1      0.506902        0.447552   \n2      -2.483871     -2.52    -2.3     -1.194018       -1.134615   \n3       0.322581      0.40     0.2      0.176380        0.159091   \n4       0.064516      0.00    -0.2     -0.026840        0.138112   \n...          ...       ...     ...           ...             ...   \n155184 -1.290323     -1.32    -1.1     -0.953988       -0.896853   \n155185 -0.129032     -0.12     0.1      0.069018        0.204545   \n155186  0.290323      0.12     0.3      0.494632        0.220280   \n155187  0.741935      0.80     1.0      1.064417        0.903846   \n155188 -0.741935     -0.68    -0.4     -0.589724       -0.620629   \n\n        Whole weight.2  Shell weight  Rings       BMI  estimated_grate  Sex_F  \\\n0            -0.133562      0.081081   11.0 -0.086155        -0.551445      1   \n1             0.756849      0.513514   11.0  0.225829         0.080510      1   \n2            -1.116438     -1.189189    6.0 -1.905680        -1.232520      0   \n3             0.270548      0.135135   10.0 -0.051725         0.131905      0   \n4            -0.041096     -0.148649    9.0 -0.098416         0.704497      0   \n...                ...           ...    ...       ...              ...    ...   \n155184       -0.955479     -0.945946    NaN -1.200028        -0.505701      0   \n155185        0.006849     -0.108108    NaN  0.453920         0.745804      1   \n155186        0.232877      0.216216    NaN  0.621418        -0.025391      0   \n155187        1.311644      1.135135    NaN  0.837427        -0.145713      1   \n155188       -0.513699     -0.727027    NaN -0.407926         0.718358      1   \n\n        Sex_I  Sex_M  \n0           0      0  \n1           0      0  \n2           1      0  \n3           0      1  \n4           1      0  \n...       ...    ...  \n155184      1      0  \n155185      0      0  \n155186      1      0  \n155187      0      0  \n155188      0      0  \n\n[155189 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Whole weight.1</th>\n      <th>Whole weight.2</th>\n      <th>Shell weight</th>\n      <th>Rings</th>\n      <th>BMI</th>\n      <th>estimated_grate</th>\n      <th>Sex_F</th>\n      <th>Sex_I</th>\n      <th>Sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.032258</td>\n      <td>0.04</td>\n      <td>0.2</td>\n      <td>-0.042945</td>\n      <td>-0.005245</td>\n      <td>-0.133562</td>\n      <td>0.081081</td>\n      <td>11.0</td>\n      <td>-0.086155</td>\n      <td>-0.551445</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.548387</td>\n      <td>0.52</td>\n      <td>0.1</td>\n      <td>0.506902</td>\n      <td>0.447552</td>\n      <td>0.756849</td>\n      <td>0.513514</td>\n      <td>11.0</td>\n      <td>0.225829</td>\n      <td>0.080510</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-2.483871</td>\n      <td>-2.52</td>\n      <td>-2.3</td>\n      <td>-1.194018</td>\n      <td>-1.134615</td>\n      <td>-1.116438</td>\n      <td>-1.189189</td>\n      <td>6.0</td>\n      <td>-1.905680</td>\n      <td>-1.232520</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.322581</td>\n      <td>0.40</td>\n      <td>0.2</td>\n      <td>0.176380</td>\n      <td>0.159091</td>\n      <td>0.270548</td>\n      <td>0.135135</td>\n      <td>10.0</td>\n      <td>-0.051725</td>\n      <td>0.131905</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.064516</td>\n      <td>0.00</td>\n      <td>-0.2</td>\n      <td>-0.026840</td>\n      <td>0.138112</td>\n      <td>-0.041096</td>\n      <td>-0.148649</td>\n      <td>9.0</td>\n      <td>-0.098416</td>\n      <td>0.704497</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>155184</th>\n      <td>-1.290323</td>\n      <td>-1.32</td>\n      <td>-1.1</td>\n      <td>-0.953988</td>\n      <td>-0.896853</td>\n      <td>-0.955479</td>\n      <td>-0.945946</td>\n      <td>NaN</td>\n      <td>-1.200028</td>\n      <td>-0.505701</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>155185</th>\n      <td>-0.129032</td>\n      <td>-0.12</td>\n      <td>0.1</td>\n      <td>0.069018</td>\n      <td>0.204545</td>\n      <td>0.006849</td>\n      <td>-0.108108</td>\n      <td>NaN</td>\n      <td>0.453920</td>\n      <td>0.745804</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>155186</th>\n      <td>0.290323</td>\n      <td>0.12</td>\n      <td>0.3</td>\n      <td>0.494632</td>\n      <td>0.220280</td>\n      <td>0.232877</td>\n      <td>0.216216</td>\n      <td>NaN</td>\n      <td>0.621418</td>\n      <td>-0.025391</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>155187</th>\n      <td>0.741935</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>1.064417</td>\n      <td>0.903846</td>\n      <td>1.311644</td>\n      <td>1.135135</td>\n      <td>NaN</td>\n      <td>0.837427</td>\n      <td>-0.145713</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>155188</th>\n      <td>-0.741935</td>\n      <td>-0.68</td>\n      <td>-0.4</td>\n      <td>-0.589724</td>\n      <td>-0.620629</td>\n      <td>-0.513699</td>\n      <td>-0.727027</td>\n      <td>NaN</td>\n      <td>-0.407926</td>\n      <td>0.718358</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>155189 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# 훈련 데이터와 테스트 데이터 나누기\ntrain_encoded = data_encoded[~pd.isnull(data_encoded['Rings'])]\ntest_encoded = data_encoded[pd.isnull(data_encoded['Rings'])]\ntest_encoded = test_encoded.drop([\"Rings\"],axis=1)","metadata":{"id":"6Ij1rQ-M9nVp","execution":{"iopub.status.busy":"2024-04-24T00:49:58.986736Z","iopub.execute_input":"2024-04-24T00:49:58.987143Z","iopub.status.idle":"2024-04-24T00:49:59.133122Z","shell.execute_reply.started":"2024-04-24T00:49:58.987114Z","shell.execute_reply":"2024-04-24T00:49:59.131733Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# # Rings 피처에 로그 변환 적용 -> 이유 : 평가기준이 rmsle임 -> 근데 뒤에 모델에서 로그변환해줌\n# features_to_transform = ['Rings']\n# for feature in features_to_transform:\n#     train_encoded[feature] = np.log1p(train_encoded[feature])","metadata":{"id":"GbXMyj2MOj2a","execution":{"iopub.status.busy":"2024-04-24T00:50:01.013596Z","iopub.execute_input":"2024-04-24T00:50:01.014893Z","iopub.status.idle":"2024-04-24T00:50:01.019608Z","shell.execute_reply.started":"2024-04-24T00:50:01.014848Z","shell.execute_reply":"2024-04-24T00:50:01.018520Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# 모델 학습(cat, lgbm, k-fold 교차검증)","metadata":{"id":"Fd0MedWhIUQc"}},{"cell_type":"code","source":"X_train = train_encoded.drop('Rings',axis=1)\ny_train = train_encoded['Rings']\nX_test = test_encoded","metadata":{"id":"vCXu5PFqOtuD","execution":{"iopub.status.busy":"2024-04-24T00:50:05.226541Z","iopub.execute_input":"2024-04-24T00:50:05.226977Z","iopub.status.idle":"2024-04-24T00:50:05.238791Z","shell.execute_reply.started":"2024-04-24T00:50:05.226943Z","shell.execute_reply":"2024-04-24T00:50:05.237306Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# !pip install -q catboost","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_U0rZMHH_12o","outputId":"c2b4eede-1d02-417a-918f-659ede715ec1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25h"}]},{"cell_type":"code","source":"# !pip install -q optuna","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBvKmft81h8A","outputId":"2061d816-0086-43e8-8869-333b31c6c7df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25h"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_log_error\n\nfrom sklearn.ensemble import VotingRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nimport optuna\nfrom optuna import Trial\nfrom optuna.samplers import TPESampler\nimport optuna\nfrom optuna import Trial\nfrom optuna.samplers import TPESampler\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"id":"j0kruDWe1Zj4","execution":{"iopub.status.busy":"2024-04-24T00:50:11.571136Z","iopub.execute_input":"2024-04-24T00:50:11.571535Z","iopub.status.idle":"2024-04-24T00:50:14.500246Z","shell.execute_reply.started":"2024-04-24T00:50:11.571504Z","shell.execute_reply":"2024-04-24T00:50:14.499036Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#kf = KFold(n_splits=5, shuffle=True, random_state=42)\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"id":"BIlfkbOK06gd","execution":{"iopub.status.busy":"2024-04-24T00:50:14.502568Z","iopub.execute_input":"2024-04-24T00:50:14.503813Z","iopub.status.idle":"2024-04-24T00:50:14.510305Z","shell.execute_reply.started":"2024-04-24T00:50:14.503765Z","shell.execute_reply":"2024-04-24T00:50:14.508990Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def rmsle(y_true, y_pred):\n    \"\"\"Calculate RMSLE (Root Mean Squared Logarithmic Error).\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))","metadata":{"id":"rSJUHbL35LlP","execution":{"iopub.status.busy":"2024-04-24T00:50:15.774834Z","iopub.execute_input":"2024-04-24T00:50:15.775229Z","iopub.status.idle":"2024-04-24T00:50:15.781533Z","shell.execute_reply.started":"2024-04-24T00:50:15.775199Z","shell.execute_reply":"2024-04-24T00:50:15.780017Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Optimize LightGBM\ndef optimize_lgb(trial: Trial):\n    # LightGBM parameters\n    params = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'device': 'cpu',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'random_state': 42,\n        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n        'max_depth': trial.suggest_int('max_depth', 4, 12),\n        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0, 0.1),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0, 0.1),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n    }\n\n    # KFold for cross-validation\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    cv_scores = []\n\n    # Cross-validation loop\n    for fold, (train_indices, valid_indices) in enumerate(kf.split(X_train, y_train)):\n        X_train_fold, X_valid_fold = X_train.iloc[train_indices], X_train.iloc[valid_indices]\n        y_train_fold, y_valid_fold = np.log1p(y_train.iloc[train_indices]), np.log1p(y_train.iloc[valid_indices])\n\n        # Train the model\n        model = LGBMRegressor(**params)\n        model.fit(X_train_fold, y_train_fold)\n\n        # Calculate RMSLE on validation data\n        valid_pred = model.predict(X_valid_fold)\n        valid_pred = np.expm1(valid_pred)  # Convert back from logarithmic scale\n        cv_score = rmsle(np.expm1(y_valid_fold), valid_pred)\n        cv_scores.append(cv_score)\n\n    # Return average RMSLE across folds\n    return np.mean(cv_scores)","metadata":{"id":"ooJ1L8ZQ1GMn","execution":{"iopub.status.busy":"2024-04-24T00:50:16.589996Z","iopub.execute_input":"2024-04-24T00:50:16.590367Z","iopub.status.idle":"2024-04-24T00:50:16.603452Z","shell.execute_reply.started":"2024-04-24T00:50:16.590338Z","shell.execute_reply":"2024-04-24T00:50:16.602448Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Optimize CatBoost\ndef optimize_cat(trial: Trial):\n    # CatBoost parameters\n    params = {\n        'loss_function': 'RMSE',\n        'eval_metric': 'RMSE',\n        'task_type': 'CPU',\n        'random_seed': 42,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n        'depth': trial.suggest_int('depth', 4, 12),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0, 1),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n        'border_count': trial.suggest_int('border_count', 32, 255),\n        'iterations': trial.suggest_int('iterations', 100, 1500),\n        'grow_policy': 'Depthwise',\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n    }\n\n    # KFold for cross-validation\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    cv_scores = []\n\n    # Cross-validation loop\n    for fold, (train_indices, valid_indices) in enumerate(kf.split(X_train, y_train)):\n        X_train_fold, X_valid_fold = X_train.iloc[train_indices], X_train.iloc[valid_indices]\n        y_train_fold, y_valid_fold = np.log1p(y_train.iloc[train_indices]), np.log1p(y_train.iloc[valid_indices])\n\n        # Train the model\n        model = CatBoostRegressor( **params, silent=True)\n        model.fit(X_train_fold, y_train_fold)\n\n        # Calculate RMSLE on validation data\n        valid_pred = model.predict(X_valid_fold)\n        valid_pred = np.expm1(valid_pred)\n        cv_score = rmsle(np.expm1(y_valid_fold), valid_pred)\n        cv_scores.append(cv_score)\n\n    # Return average RMSLE across folds\n    return np.mean(cv_scores)","metadata":{"id":"u0Q1fbuL1OO-","execution":{"iopub.status.busy":"2024-04-24T00:50:17.578750Z","iopub.execute_input":"2024-04-24T00:50:17.579166Z","iopub.status.idle":"2024-04-24T00:50:17.592329Z","shell.execute_reply.started":"2024-04-24T00:50:17.579133Z","shell.execute_reply":"2024-04-24T00:50:17.590733Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Optuna studies for parameter optimization\nlgb_study = optuna.create_study(direction='minimize', sampler=TPESampler())\n\n# Optimize parameters for 25 trials\nlgb_study.optimize(optimize_lgb, n_trials=25)\n\n# Get best parameters for each model\nlgb_params = lgb_study.best_params\n\nprint(\"Optimized LightGBM Parameters:\", lgb_params)\n\n# Optimized LightGBM Parameters: {'num_leaves': 82, 'learning_rate': 0.022426366984409564, 'max_depth': 8, 'min_child_samples': 93,\n#                                 'reg_alpha': 0.019998102319508396, 'reg_lambda': 0.04219735229323243,\n#                                 'subsample': 0.9911492271338408, 'colsample_bytree': 0.6300902724449493, 'n_estimators': 1389}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7l_bAgIz1Skn","outputId":"9441f3c2-ae26-446a-842b-02f7203ee434","execution":{"iopub.status.busy":"2024-04-24T00:50:18.525696Z","iopub.execute_input":"2024-04-24T00:50:18.526543Z","iopub.status.idle":"2024-04-24T01:05:11.335534Z","shell.execute_reply.started":"2024-04-24T00:50:18.526492Z","shell.execute_reply":"2024-04-24T01:05:11.334131Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"[I 2024-04-24 00:50:18,530] A new study created in memory with name: no-name-a22788b1-5122-490f-815f-51817e94c8d0\n[I 2024-04-24 00:50:28,187] Trial 0 finished with value: 0.14948956201683378 and parameters: {'num_leaves': 36, 'learning_rate': 0.0925223697144595, 'max_depth': 11, 'min_child_samples': 21, 'reg_alpha': 0.08788009368994384, 'reg_lambda': 0.03405974059154193, 'subsample': 0.7406683691528686, 'colsample_bytree': 0.6957705711564633, 'n_estimators': 209}. Best is trial 0 with value: 0.14948956201683378.\n[I 2024-04-24 00:50:36,644] Trial 1 finished with value: 0.15325495970675246 and parameters: {'num_leaves': 79, 'learning_rate': 0.0341792748399411, 'max_depth': 4, 'min_child_samples': 20, 'reg_alpha': 0.09584765673472363, 'reg_lambda': 0.09898739577722035, 'subsample': 0.56063420467825, 'colsample_bytree': 0.997984269099149, 'n_estimators': 142}. Best is trial 0 with value: 0.14948956201683378.\n[I 2024-04-24 00:51:18,355] Trial 2 finished with value: 0.1490834622891941 and parameters: {'num_leaves': 24, 'learning_rate': 0.07347200357238529, 'max_depth': 8, 'min_child_samples': 45, 'reg_alpha': 0.0725257421351688, 'reg_lambda': 0.05471046607142195, 'subsample': 0.968090474199973, 'colsample_bytree': 0.6622875150388052, 'n_estimators': 1177}. Best is trial 2 with value: 0.1490834622891941.\n[I 2024-04-24 00:51:59,462] Trial 3 finished with value: 0.14903171585865244 and parameters: {'num_leaves': 32, 'learning_rate': 0.024901351652373078, 'max_depth': 11, 'min_child_samples': 58, 'reg_alpha': 0.007562233054399659, 'reg_lambda': 0.011714902141566475, 'subsample': 0.6744655615370678, 'colsample_bytree': 0.6379078271849862, 'n_estimators': 909}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:52:20,641] Trial 4 finished with value: 0.14932122662859346 and parameters: {'num_leaves': 49, 'learning_rate': 0.044571084052873806, 'max_depth': 10, 'min_child_samples': 19, 'reg_alpha': 0.058368384023972965, 'reg_lambda': 0.06659565226288137, 'subsample': 0.7407173317297511, 'colsample_bytree': 0.799412170784394, 'n_estimators': 396}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:52:56,861] Trial 5 finished with value: 0.14962310405316348 and parameters: {'num_leaves': 53, 'learning_rate': 0.02229271220651867, 'max_depth': 11, 'min_child_samples': 43, 'reg_alpha': 0.03859151717434017, 'reg_lambda': 0.011606195095843331, 'subsample': 0.5890874544301667, 'colsample_bytree': 0.9756808256185057, 'n_estimators': 521}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:53:06,893] Trial 6 finished with value: 0.1495881577762966 and parameters: {'num_leaves': 55, 'learning_rate': 0.09519556966925588, 'max_depth': 9, 'min_child_samples': 19, 'reg_alpha': 0.020514483422726527, 'reg_lambda': 0.09012995410978471, 'subsample': 0.7172001280681158, 'colsample_bytree': 0.8940290800528996, 'n_estimators': 161}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:54:01,646] Trial 7 finished with value: 0.15565089295928508 and parameters: {'num_leaves': 55, 'learning_rate': 0.19200023568826335, 'max_depth': 9, 'min_child_samples': 10, 'reg_alpha': 0.07073314384705141, 'reg_lambda': 0.008223993507562722, 'subsample': 0.7080355297139562, 'colsample_bytree': 0.6178343137542395, 'n_estimators': 1499}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:54:58,744] Trial 8 finished with value: 0.15250514965867018 and parameters: {'num_leaves': 29, 'learning_rate': 0.17160722411780782, 'max_depth': 11, 'min_child_samples': 63, 'reg_alpha': 0.09698064054855984, 'reg_lambda': 0.04570960068497111, 'subsample': 0.7818291524952528, 'colsample_bytree': 0.7615883619283599, 'n_estimators': 1481}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:55:30,109] Trial 9 finished with value: 0.15078411230591426 and parameters: {'num_leaves': 53, 'learning_rate': 0.17936835901278164, 'max_depth': 5, 'min_child_samples': 15, 'reg_alpha': 0.022695882529539847, 'reg_lambda': 0.015493551705743281, 'subsample': 0.9913248111937885, 'colsample_bytree': 0.5035461180726317, 'n_estimators': 1053}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:55:58,888] Trial 10 finished with value: 0.1496966412733341 and parameters: {'num_leaves': 100, 'learning_rate': 0.137095912689322, 'max_depth': 7, 'min_child_samples': 95, 'reg_alpha': 0.0027288415989586614, 'reg_lambda': 0.02908315232850586, 'subsample': 0.8640256091243682, 'colsample_bytree': 0.5452166147121078, 'n_estimators': 760}. Best is trial 3 with value: 0.14903171585865244.\n[I 2024-04-24 00:56:38,455] Trial 11 finished with value: 0.14884995742170903 and parameters: {'num_leaves': 21, 'learning_rate': 0.06451928233035385, 'max_depth': 6, 'min_child_samples': 58, 'reg_alpha': 0.0713358952990177, 'reg_lambda': 0.06434397377049461, 'subsample': 0.9878955061657134, 'colsample_bytree': 0.6536513368372486, 'n_estimators': 1123}. Best is trial 11 with value: 0.14884995742170903.\n[I 2024-04-24 00:57:17,796] Trial 12 finished with value: 0.1487963506614855 and parameters: {'num_leaves': 37, 'learning_rate': 0.05919225219916775, 'max_depth': 7, 'min_child_samples': 74, 'reg_alpha': 0.04475070625583179, 'reg_lambda': 0.07719730301675437, 'subsample': 0.633968459250466, 'colsample_bytree': 0.6139912553908831, 'n_estimators': 992}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 00:58:03,499] Trial 13 finished with value: 0.14891903134282955 and parameters: {'num_leaves': 39, 'learning_rate': 0.06205124526394798, 'max_depth': 6, 'min_child_samples': 77, 'reg_alpha': 0.04340297443511893, 'reg_lambda': 0.07566471383415548, 'subsample': 0.5049212990171712, 'colsample_bytree': 0.578239012429734, 'n_estimators': 1257}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 00:58:29,540] Trial 14 finished with value: 0.14910422142112362 and parameters: {'num_leaves': 20, 'learning_rate': 0.12308679454447426, 'max_depth': 6, 'min_child_samples': 76, 'reg_alpha': 0.05786705543105866, 'reg_lambda': 0.07614212901652304, 'subsample': 0.8688037191838328, 'colsample_bytree': 0.7127347952734333, 'n_estimators': 741}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 00:59:14,388] Trial 15 finished with value: 0.14926484521984323 and parameters: {'num_leaves': 72, 'learning_rate': 0.06941770950402101, 'max_depth': 7, 'min_child_samples': 76, 'reg_alpha': 0.07457191321566892, 'reg_lambda': 0.05968103244724707, 'subsample': 0.6407424200815783, 'colsample_bytree': 0.8291073226281762, 'n_estimators': 960}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 00:59:51,411] Trial 16 finished with value: 0.14899150971981948 and parameters: {'num_leaves': 41, 'learning_rate': 0.051296247615669255, 'max_depth': 4, 'min_child_samples': 100, 'reg_alpha': 0.0298408527801481, 'reg_lambda': 0.08162084680576959, 'subsample': 0.8228891573903276, 'colsample_bytree': 0.5895563076492449, 'n_estimators': 1260}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 01:00:27,670] Trial 17 finished with value: 0.1507082713422892 and parameters: {'num_leaves': 70, 'learning_rate': 0.011595498472358225, 'max_depth': 6, 'min_child_samples': 43, 'reg_alpha': 0.055502132188568185, 'reg_lambda': 0.042537158128509375, 'subsample': 0.9142462932922688, 'colsample_bytree': 0.721984354901422, 'n_estimators': 581}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 01:01:05,023] Trial 18 finished with value: 0.14939596390570556 and parameters: {'num_leaves': 20, 'learning_rate': 0.11505054911639326, 'max_depth': 8, 'min_child_samples': 89, 'reg_alpha': 0.08126186503305322, 'reg_lambda': 0.06618376927318584, 'subsample': 0.6249513877529858, 'colsample_bytree': 0.6599493140178534, 'n_estimators': 1068}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 01:01:47,126] Trial 19 finished with value: 0.14894128734674889 and parameters: {'num_leaves': 43, 'learning_rate': 0.07915269290566741, 'max_depth': 5, 'min_child_samples': 67, 'reg_alpha': 0.04617176438080884, 'reg_lambda': 0.09812496943777561, 'subsample': 0.5046331276140068, 'colsample_bytree': 0.5075297486092649, 'n_estimators': 1373}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 01:02:21,005] Trial 20 finished with value: 0.1501742086545605 and parameters: {'num_leaves': 29, 'learning_rate': 0.1507807778957187, 'max_depth': 7, 'min_child_samples': 52, 'reg_alpha': 0.06456304130753755, 'reg_lambda': 0.08403719962145786, 'subsample': 0.7986248119594732, 'colsample_bytree': 0.7686555352691116, 'n_estimators': 864}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 01:03:06,290] Trial 21 finished with value: 0.14880503748168242 and parameters: {'num_leaves': 41, 'learning_rate': 0.059264974951938, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0.04362648936835647, 'reg_lambda': 0.07132758537241705, 'subsample': 0.5269782710608918, 'colsample_bytree': 0.5793894484202498, 'n_estimators': 1234}. Best is trial 12 with value: 0.1487963506614855.\n[I 2024-04-24 01:03:42,963] Trial 22 finished with value: 0.1487951155597944 and parameters: {'num_leaves': 45, 'learning_rate': 0.0507079405457648, 'max_depth': 5, 'min_child_samples': 82, 'reg_alpha': 0.03489440014020029, 'reg_lambda': 0.06783469176235944, 'subsample': 0.5766440152329765, 'colsample_bytree': 0.5657223516572074, 'n_estimators': 1101}. Best is trial 22 with value: 0.1487951155597944.\n[I 2024-04-24 01:04:26,256] Trial 23 finished with value: 0.14877346345723433 and parameters: {'num_leaves': 62, 'learning_rate': 0.04788121504206421, 'max_depth': 5, 'min_child_samples': 86, 'reg_alpha': 0.03673166900832083, 'reg_lambda': 0.07168630607247035, 'subsample': 0.5619115053764009, 'colsample_bytree': 0.5666208447654005, 'n_estimators': 1315}. Best is trial 23 with value: 0.14877346345723433.\n[I 2024-04-24 01:05:11,329] Trial 24 finished with value: 0.1487891334771257 and parameters: {'num_leaves': 65, 'learning_rate': 0.04263119390230315, 'max_depth': 5, 'min_child_samples': 88, 'reg_alpha': 0.03208349989785813, 'reg_lambda': 0.053950914340998954, 'subsample': 0.5802282949410843, 'colsample_bytree': 0.5451959151591504, 'n_estimators': 1358}. Best is trial 23 with value: 0.14877346345723433.\n","output_type":"stream"},{"name":"stdout","text":"Optimized LightGBM Parameters: {'num_leaves': 62, 'learning_rate': 0.04788121504206421, 'max_depth': 5, 'min_child_samples': 86, 'reg_alpha': 0.03673166900832083, 'reg_lambda': 0.07168630607247035, 'subsample': 0.5619115053764009, 'colsample_bytree': 0.5666208447654005, 'n_estimators': 1315}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Optuna studies for parameter optimization\ncat_study = optuna.create_study(direction='minimize', sampler=TPESampler())\n\n# Optimize parameters for 25 trials\ncat_study.optimize(optimize_cat, n_trials=25)\n\n# Get best parameters for each model\ncat_params = cat_study.best_params\n\nprint(\"Optimized CatBoost Parameters:\", cat_params)\n\n# Optimized CatBoost Parameters: {'learning_rate': 0.03257120578901709, 'depth': 9, 'l2_leaf_reg': 0.3766477794828306,\n#                                 'bagging_temperature': 0.6058786846647075, 'border_count': 228, 'iterations': 1070, 'min_data_in_leaf': 39}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlB8nn9ZACrP","outputId":"04fdabc0-a8f0-44dc-80ca-7ae2b4d1e51c","execution":{"iopub.status.busy":"2024-04-24T01:05:11.337942Z","iopub.execute_input":"2024-04-24T01:05:11.338291Z","iopub.status.idle":"2024-04-24T01:41:55.561600Z","shell.execute_reply.started":"2024-04-24T01:05:11.338261Z","shell.execute_reply":"2024-04-24T01:41:55.560179Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"[I 2024-04-24 01:05:11,340] A new study created in memory with name: no-name-4600d44c-1547-4d96-978a-72eafaa978cb\n[I 2024-04-24 01:06:28,247] Trial 0 finished with value: 0.15044087315369162 and parameters: {'learning_rate': 0.024830883559300153, 'depth': 12, 'l2_leaf_reg': 0.96857291558318, 'bagging_temperature': 0.535594503377292, 'border_count': 111, 'iterations': 283, 'min_data_in_leaf': 81}. Best is trial 0 with value: 0.15044087315369162.\n[I 2024-04-24 01:08:18,505] Trial 1 finished with value: 0.1554921715270894 and parameters: {'learning_rate': 0.17046647500505108, 'depth': 7, 'l2_leaf_reg': 0.3040422358029812, 'bagging_temperature': 0.810888128773999, 'border_count': 135, 'iterations': 1015, 'min_data_in_leaf': 1}. Best is trial 0 with value: 0.15044087315369162.\n[I 2024-04-24 01:08:39,949] Trial 2 finished with value: 0.1513244129201517 and parameters: {'learning_rate': 0.08402716787589135, 'depth': 9, 'l2_leaf_reg': 0.4952288675063976, 'bagging_temperature': 0.14140196024327714, 'border_count': 34, 'iterations': 153, 'min_data_in_leaf': 67}. Best is trial 0 with value: 0.15044087315369162.\n[I 2024-04-24 01:09:47,112] Trial 3 finished with value: 0.14960007373147885 and parameters: {'learning_rate': 0.08914837111154204, 'depth': 5, 'l2_leaf_reg': 0.8441298960334483, 'bagging_temperature': 0.27072463310848927, 'border_count': 179, 'iterations': 926, 'min_data_in_leaf': 51}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:10:27,379] Trial 4 finished with value: 0.15104492346539708 and parameters: {'learning_rate': 0.02388721733806126, 'depth': 6, 'l2_leaf_reg': 0.9344534404515493, 'bagging_temperature': 0.9706579080229135, 'border_count': 131, 'iterations': 431, 'min_data_in_leaf': 1}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:11:34,564] Trial 5 finished with value: 0.15049913363154616 and parameters: {'learning_rate': 0.14608985862502494, 'depth': 6, 'l2_leaf_reg': 0.9135922716472926, 'bagging_temperature': 0.7780251115828696, 'border_count': 226, 'iterations': 779, 'min_data_in_leaf': 24}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:13:05,784] Trial 6 finished with value: 0.1534457133908199 and parameters: {'learning_rate': 0.17739622958760595, 'depth': 5, 'l2_leaf_reg': 0.5379073952045278, 'bagging_temperature': 0.35550801941310994, 'border_count': 52, 'iterations': 1312, 'min_data_in_leaf': 49}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:15:08,822] Trial 7 finished with value: 0.151565132822101 and parameters: {'learning_rate': 0.09335345416789392, 'depth': 7, 'l2_leaf_reg': 0.018532847184733914, 'bagging_temperature': 0.9604625962261466, 'border_count': 130, 'iterations': 1250, 'min_data_in_leaf': 47}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:16:23,728] Trial 8 finished with value: 0.15004517703652934 and parameters: {'learning_rate': 0.04172617637839805, 'depth': 8, 'l2_leaf_reg': 0.4324494576915311, 'bagging_temperature': 0.30466893947111273, 'border_count': 111, 'iterations': 630, 'min_data_in_leaf': 55}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:16:54,062] Trial 9 finished with value: 0.15016554085470551 and parameters: {'learning_rate': 0.19399085013108402, 'depth': 4, 'l2_leaf_reg': 0.22645215786290307, 'bagging_temperature': 0.9932012846213826, 'border_count': 196, 'iterations': 504, 'min_data_in_leaf': 6}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:19:18,673] Trial 10 finished with value: 0.15235114797413676 and parameters: {'learning_rate': 0.1239330071900065, 'depth': 10, 'l2_leaf_reg': 0.70432191402065, 'bagging_temperature': 0.13619134887459805, 'border_count': 184, 'iterations': 985, 'min_data_in_leaf': 99}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:20:57,550] Trial 11 finished with value: 0.15107488699620775 and parameters: {'learning_rate': 0.05971779203554217, 'depth': 9, 'l2_leaf_reg': 0.7025228233837344, 'bagging_temperature': 0.3424392720036153, 'border_count': 76, 'iterations': 739, 'min_data_in_leaf': 33}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:21:34,382] Trial 12 finished with value: 0.1502366742839844 and parameters: {'learning_rate': 0.05651222397256464, 'depth': 4, 'l2_leaf_reg': 0.44657772974972937, 'bagging_temperature': 0.3335712602098015, 'border_count': 175, 'iterations': 602, 'min_data_in_leaf': 62}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:24:19,875] Trial 13 finished with value: 0.15197665774368083 and parameters: {'learning_rate': 0.05835557069398495, 'depth': 11, 'l2_leaf_reg': 0.743027020307759, 'bagging_temperature': 0.4896077837148096, 'border_count': 91, 'iterations': 1006, 'min_data_in_leaf': 67}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:27:13,903] Trial 14 finished with value: 0.15353173656168642 and parameters: {'learning_rate': 0.12353431708201905, 'depth': 8, 'l2_leaf_reg': 0.31102612835445453, 'bagging_temperature': 0.24423649236533496, 'border_count': 253, 'iterations': 1469, 'min_data_in_leaf': 31}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:28:14,858] Trial 15 finished with value: 0.15167912929522387 and parameters: {'learning_rate': 0.010371342219085637, 'depth': 6, 'l2_leaf_reg': 0.6285668485392563, 'bagging_temperature': 0.44699760775092867, 'border_count': 150, 'iterations': 645, 'min_data_in_leaf': 80}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:30:03,935] Trial 16 finished with value: 0.15040838883038116 and parameters: {'learning_rate': 0.0706577904347778, 'depth': 8, 'l2_leaf_reg': 0.1360160607088411, 'bagging_temperature': 0.6715020018587403, 'border_count': 162, 'iterations': 934, 'min_data_in_leaf': 42}. Best is trial 3 with value: 0.14960007373147885.\n[I 2024-04-24 01:31:29,949] Trial 17 finished with value: 0.14941930047947724 and parameters: {'learning_rate': 0.04255834998908554, 'depth': 5, 'l2_leaf_reg': 0.8137201161107486, 'bagging_temperature': 0.24402888531001393, 'border_count': 208, 'iterations': 1199, 'min_data_in_leaf': 59}. Best is trial 17 with value: 0.14941930047947724.\n[I 2024-04-24 01:32:57,784] Trial 18 finished with value: 0.1497424973338957 and parameters: {'learning_rate': 0.10953174637764754, 'depth': 5, 'l2_leaf_reg': 0.8065069501049692, 'bagging_temperature': 0.20015117812804206, 'border_count': 212, 'iterations': 1208, 'min_data_in_leaf': 79}. Best is trial 17 with value: 0.14941930047947724.\n[I 2024-04-24 01:34:18,448] Trial 19 finished with value: 0.1493956249046538 and parameters: {'learning_rate': 0.08094543141023366, 'depth': 5, 'l2_leaf_reg': 0.8321469746669462, 'bagging_temperature': 0.4261687491636644, 'border_count': 238, 'iterations': 1127, 'min_data_in_leaf': 20}. Best is trial 19 with value: 0.1493956249046538.\n[I 2024-04-24 01:35:46,523] Trial 20 finished with value: 0.1495578900614062 and parameters: {'learning_rate': 0.03914856884276675, 'depth': 4, 'l2_leaf_reg': 0.6038231547578545, 'bagging_temperature': 0.6128469958338213, 'border_count': 254, 'iterations': 1472, 'min_data_in_leaf': 16}. Best is trial 19 with value: 0.1493956249046538.\n[I 2024-04-24 01:37:15,555] Trial 21 finished with value: 0.1495006763126674 and parameters: {'learning_rate': 0.0408182647674689, 'depth': 4, 'l2_leaf_reg': 0.8243880065432245, 'bagging_temperature': 0.415899577871557, 'border_count': 255, 'iterations': 1496, 'min_data_in_leaf': 15}. Best is trial 19 with value: 0.1493956249046538.\n[I 2024-04-24 01:38:37,670] Trial 22 finished with value: 0.1493907776386762 and parameters: {'learning_rate': 0.044111429208432126, 'depth': 5, 'l2_leaf_reg': 0.8409192102436466, 'bagging_temperature': 0.41505431766033685, 'border_count': 231, 'iterations': 1134, 'min_data_in_leaf': 12}. Best is trial 22 with value: 0.1493907776386762.\n[I 2024-04-24 01:39:58,810] Trial 23 finished with value: 0.14942748715973064 and parameters: {'learning_rate': 0.06597672532938642, 'depth': 5, 'l2_leaf_reg': 0.8776853923444059, 'bagging_temperature': 0.43763936258542724, 'border_count': 221, 'iterations': 1139, 'min_data_in_leaf': 15}. Best is trial 22 with value: 0.1493907776386762.\n[I 2024-04-24 01:41:55,555] Trial 24 finished with value: 0.14917847473138401 and parameters: {'learning_rate': 0.03194139436986193, 'depth': 7, 'l2_leaf_reg': 0.7724715760932627, 'bagging_temperature': 0.5762951295221982, 'border_count': 232, 'iterations': 1115, 'min_data_in_leaf': 39}. Best is trial 24 with value: 0.14917847473138401.\n","output_type":"stream"},{"name":"stdout","text":"Optimized CatBoost Parameters: {'learning_rate': 0.03194139436986193, 'depth': 7, 'l2_leaf_reg': 0.7724715760932627, 'bagging_temperature': 0.5762951295221982, 'border_count': 232, 'iterations': 1115, 'min_data_in_leaf': 39}\n","output_type":"stream"}]},{"cell_type":"code","source":"lgb_params = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'verbosity': -1,\n    'boosting_type': 'gbdt',\n    'random_state': 42,\n    **lgb_study.best_params  # Add the optimized parameters\n}\n\ncat_params = {\n    'loss_function': 'RMSE',\n    'eval_metric': 'RMSE',\n    'devices': '0',\n    'random_seed': 42,\n    **cat_study.best_params  # Add the optimized parameters\n}","metadata":{"id":"XkWhRopC1WI_","execution":{"iopub.status.busy":"2024-04-24T01:41:55.563679Z","iopub.execute_input":"2024-04-24T01:41:55.564055Z","iopub.status.idle":"2024-04-24T01:41:55.571791Z","shell.execute_reply.started":"2024-04-24T01:41:55.564023Z","shell.execute_reply":"2024-04-24T01:41:55.570429Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# RMSLE 함수 정의\ndef rmsle(y_true, y_pred):\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n\n# Optuna의 목적 함수 정의\ndef objective(trial):\n    # 앙상블에 대한 샘플 가중치\n    weights = [trial.suggest_float(\"weight_lgbm\", 0.1, 0.9), trial.suggest_float(\"weight_catboost\", 0.1, 0.9)]\n\n    # 가중치의 합이 1이 되도록 정규화\n    total_weight = sum(weights)\n    normalized_weights = [w / total_weight for w in weights]\n\n    # 현재 가중치로 VotingRegressor 정의\n    estimators = [\n        ('lgbm', LGBMRegressor(**lgb_params)),\n        ('catboost', CatBoostRegressor(**cat_params, silent=True))\n    ]\n\n    voting_regressor = VotingRegressor(estimators=estimators, weights=normalized_weights)\n\n    # 교차 검증 객체 초기화\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n    # 교차 검증을 통해 모델 훈련 및 평가\n    cv_scores = []\n    for fold, (train_indices, valid_indices) in enumerate(kf.split(X_train, y_train)):\n        X_train_fold = X_train.iloc[train_indices]\n        y_train_fold = np.log1p(y_train.iloc[train_indices])\n\n        X_valid_fold = X_train.iloc[valid_indices]\n        y_valid_fold = np.log1p(y_train.iloc[valid_indices])\n\n        # 현재 가중치로 모델 훈련\n        voting_regressor.fit(X_train_fold, y_train_fold)\n\n        # 검증 데이터에 대한 예측 및 RMSLE 점수 계산\n        valid_pred = voting_regressor.predict(X_valid_fold)\n        valid_pred = np.expm1(valid_pred)  # 원래 척도로 변환\n\n        # 이 폴드의 RMSLE 계산 및 cv_scores에 추가\n        cv_score = rmsle(np.expm1(y_valid_fold), valid_pred)  # 원래 척도로 y_valid_fold 변환\n        cv_scores.append(cv_score)\n\n    # 모든 폴드의 평균 RMSLE 반환\n    return np.mean(cv_scores)\n\n# Optuna 스터디 설정\nstudy = optuna.create_study(direction='minimize')  # RMSLE를 최소화\nstudy.optimize(objective, n_trials=50)  # 필요한 트라이얼 수 설정\n\n# 가중치를 1로 정규화하여 합이 1이 되도록 함\ntotal_weight = sum(study.best_params.values())\nbest_weights = [value / total_weight for value in study.best_params.values()]\nprint(\"최적 RMSLE:\", study.best_value)\nprint(\"최적 가중치:\", best_weights)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSIQmG0uGBmd","outputId":"ce6ef368-29b9-44dd-9345-c8d6c53358af","execution":{"iopub.status.busy":"2024-04-24T01:41:55.574910Z","iopub.execute_input":"2024-04-24T01:41:55.575979Z","iopub.status.idle":"2024-04-24T03:09:06.047748Z","shell.execute_reply.started":"2024-04-24T01:41:55.575932Z","shell.execute_reply":"2024-04-24T03:09:06.046484Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"[I 2024-04-24 01:41:55,589] A new study created in memory with name: no-name-b83038f3-35dc-4764-b35d-a5f1a3411bef\n[I 2024-04-24 01:43:39,652] Trial 0 finished with value: 0.1488357307538207 and parameters: {'weight_lgbm': 0.3064814834909264, 'weight_catboost': 0.20238029321096188}. Best is trial 0 with value: 0.1488357307538207.\n[I 2024-04-24 01:45:23,968] Trial 1 finished with value: 0.1488294405869143 and parameters: {'weight_lgbm': 0.8990482379531505, 'weight_catboost': 0.5741259854556288}. Best is trial 1 with value: 0.1488294405869143.\n[I 2024-04-24 01:47:08,508] Trial 2 finished with value: 0.14874186988290855 and parameters: {'weight_lgbm': 0.8735679718693796, 'weight_catboost': 0.22723630006373421}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 01:48:53,411] Trial 3 finished with value: 0.14902331101609076 and parameters: {'weight_lgbm': 0.5344357195299168, 'weight_catboost': 0.7123488570170358}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 01:50:38,547] Trial 4 finished with value: 0.1493979961350082 and parameters: {'weight_lgbm': 0.2091126417688015, 'weight_catboost': 0.7877791736817289}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 01:52:23,339] Trial 5 finished with value: 0.1491236188398582 and parameters: {'weight_lgbm': 0.35789111157195685, 'weight_catboost': 0.6351086369211587}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 01:54:08,200] Trial 6 finished with value: 0.14878658182358837 and parameters: {'weight_lgbm': 0.7439161540750975, 'weight_catboost': 0.3595581786855715}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 01:55:52,714] Trial 7 finished with value: 0.14879288870852223 and parameters: {'weight_lgbm': 0.4901407353576155, 'weight_catboost': 0.24871444260939057}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 01:57:37,738] Trial 8 finished with value: 0.14916959604985108 and parameters: {'weight_lgbm': 0.18587466340062672, 'weight_catboost': 0.37378203324192283}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 01:59:22,680] Trial 9 finished with value: 0.14917749376003386 and parameters: {'weight_lgbm': 0.24407494678001396, 'weight_catboost': 0.5013825482688609}. Best is trial 2 with value: 0.14874186988290855.\n[I 2024-04-24 02:01:07,432] Trial 10 finished with value: 0.14873692639011335 and parameters: {'weight_lgbm': 0.7085872748944524, 'weight_catboost': 0.1341862109256604}. Best is trial 10 with value: 0.14873692639011335.\n[I 2024-04-24 02:02:52,016] Trial 11 finished with value: 0.14873869719005808 and parameters: {'weight_lgbm': 0.7830586208352566, 'weight_catboost': 0.1030340258199132}. Best is trial 10 with value: 0.14873692639011335.\n[I 2024-04-24 02:04:36,951] Trial 12 finished with value: 0.14873689114712535 and parameters: {'weight_lgbm': 0.7017230571505986, 'weight_catboost': 0.11718551229505789}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:06:21,942] Trial 13 finished with value: 0.14874006802627698 and parameters: {'weight_lgbm': 0.6369130069462366, 'weight_catboost': 0.15466898358411557}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:08:06,166] Trial 14 finished with value: 0.14880490965974014 and parameters: {'weight_lgbm': 0.6517415247423547, 'weight_catboost': 0.35965961998199747}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:09:51,383] Trial 15 finished with value: 0.1491029799609137 and parameters: {'weight_lgbm': 0.5272850478520894, 'weight_catboost': 0.8838597868979619}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:11:35,765] Trial 16 finished with value: 0.148776478710947 and parameters: {'weight_lgbm': 0.6878196404042748, 'weight_catboost': 0.3047565303585329}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:13:19,528] Trial 17 finished with value: 0.14873847285871553 and parameters: {'weight_lgbm': 0.7693504239628062, 'weight_catboost': 0.10329327505140035}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:15:03,497] Trial 18 finished with value: 0.14894016901819643 and parameters: {'weight_lgbm': 0.42912721194958137, 'weight_catboost': 0.4378208891869638}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:16:48,068] Trial 19 finished with value: 0.1487758849564942 and parameters: {'weight_lgbm': 0.6195728874347224, 'weight_catboost': 0.27300329449861127}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:18:32,632] Trial 20 finished with value: 0.14874561194652275 and parameters: {'weight_lgbm': 0.5787767900976887, 'weight_catboost': 0.1673073412196098}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:20:17,015] Trial 21 finished with value: 0.1487390514077947 and parameters: {'weight_lgbm': 0.796818826914704, 'weight_catboost': 0.10173216034213713}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:22:01,668] Trial 22 finished with value: 0.14873712932968694 and parameters: {'weight_lgbm': 0.744863138350133, 'weight_catboost': 0.14685189153651304}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:23:46,302] Trial 23 finished with value: 0.14874189957846587 and parameters: {'weight_lgbm': 0.7101295303926358, 'weight_catboost': 0.18490660215270588}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:25:30,201] Trial 24 finished with value: 0.14875615707186443 and parameters: {'weight_lgbm': 0.8228608139758669, 'weight_catboost': 0.2888450330216339}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:27:14,905] Trial 25 finished with value: 0.14874074254257003 and parameters: {'weight_lgbm': 0.689272586444401, 'weight_catboost': 0.1721169938249925}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:28:59,492] Trial 26 finished with value: 0.14880548650127545 and parameters: {'weight_lgbm': 0.8320039510545616, 'weight_catboost': 0.4608758920726521}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:30:44,501] Trial 27 finished with value: 0.14927726967549487 and parameters: {'weight_lgbm': 0.1137213963244641, 'weight_catboost': 0.3055607792534567}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:32:29,424] Trial 28 finished with value: 0.14874011555154631 and parameters: {'weight_lgbm': 0.5961760500605175, 'weight_catboost': 0.14507635651366524}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:34:13,692] Trial 29 finished with value: 0.1487808317408818 and parameters: {'weight_lgbm': 0.44816792930667665, 'weight_catboost': 0.20647567913658713}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:35:57,799] Trial 30 finished with value: 0.1487500139308519 and parameters: {'weight_lgbm': 0.7232125494877353, 'weight_catboost': 0.22940694387858795}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:37:41,658] Trial 31 finished with value: 0.14873869305110765 and parameters: {'weight_lgbm': 0.762209703292293, 'weight_catboost': 0.10032723948943564}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:39:26,271] Trial 32 finished with value: 0.148736917302105 and parameters: {'weight_lgbm': 0.8494234019428817, 'weight_catboost': 0.14066912008839103}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:41:11,268] Trial 33 finished with value: 0.148739814458193 and parameters: {'weight_lgbm': 0.8945207713638531, 'weight_catboost': 0.21477422860639872}. Best is trial 12 with value: 0.14873689114712535.\n[I 2024-04-24 02:42:56,391] Trial 34 finished with value: 0.14873682060816362 and parameters: {'weight_lgbm': 0.8372457038490222, 'weight_catboost': 0.14448350713368138}. Best is trial 34 with value: 0.14873682060816362.\n[I 2024-04-24 02:44:39,880] Trial 35 finished with value: 0.1488311340762894 and parameters: {'weight_lgbm': 0.8620496387086988, 'weight_catboost': 0.5555569846540623}. Best is trial 34 with value: 0.14873682060816362.\n[I 2024-04-24 02:46:25,287] Trial 36 finished with value: 0.1487451667163433 and parameters: {'weight_lgbm': 0.8415268118930093, 'weight_catboost': 0.24062654097379338}. Best is trial 34 with value: 0.14873682060816362.\n[I 2024-04-24 02:48:10,941] Trial 37 finished with value: 0.14876826696699147 and parameters: {'weight_lgbm': 0.8092440769283751, 'weight_catboost': 0.3303678573520036}. Best is trial 34 with value: 0.14873682060816362.\n[I 2024-04-24 02:49:55,448] Trial 38 finished with value: 0.14886451192181285 and parameters: {'weight_lgbm': 0.8994886561462307, 'weight_catboost': 0.6824345025236563}. Best is trial 34 with value: 0.14873682060816362.\n[I 2024-04-24 02:51:39,107] Trial 39 finished with value: 0.14876129691191461 and parameters: {'weight_lgbm': 0.6771589739686046, 'weight_catboost': 0.2549080193778763}. Best is trial 34 with value: 0.14873682060816362.\n[I 2024-04-24 02:53:23,191] Trial 40 finished with value: 0.1488545393930479 and parameters: {'weight_lgbm': 0.5695887023045008, 'weight_catboost': 0.4127998698014643}. Best is trial 34 with value: 0.14873682060816362.\n[I 2024-04-24 02:55:06,944] Trial 41 finished with value: 0.14873681733257096 and parameters: {'weight_lgbm': 0.766997381576382, 'weight_catboost': 0.1390573593689939}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 02:56:50,083] Trial 42 finished with value: 0.1487373399324882 and parameters: {'weight_lgbm': 0.8554130002509814, 'weight_catboost': 0.13039398509327635}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 02:58:34,083] Trial 43 finished with value: 0.14873918660728175 and parameters: {'weight_lgbm': 0.7896379131300243, 'weight_catboost': 0.18384771769706315}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 03:00:19,914] Trial 44 finished with value: 0.14874244989029123 and parameters: {'weight_lgbm': 0.7589622684573445, 'weight_catboost': 0.20119361683148768}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 03:02:05,910] Trial 45 finished with value: 0.14873711209936347 and parameters: {'weight_lgbm': 0.7254319185639821, 'weight_catboost': 0.14262629194758347}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 03:03:51,568] Trial 46 finished with value: 0.14873734179997422 and parameters: {'weight_lgbm': 0.6683539892619615, 'weight_catboost': 0.1356609801400476}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 03:05:36,579] Trial 47 finished with value: 0.1492208562645773 and parameters: {'weight_lgbm': 0.34593186624283156, 'weight_catboost': 0.7984289382827012}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 03:07:20,944] Trial 48 finished with value: 0.14874187823820795 and parameters: {'weight_lgbm': 0.8758362313862262, 'weight_catboost': 0.2278904545247787}. Best is trial 41 with value: 0.14873681733257096.\n[I 2024-04-24 03:09:06,040] Trial 49 finished with value: 0.14873820418176037 and parameters: {'weight_lgbm': 0.8082990384267414, 'weight_catboost': 0.1773162976965372}. Best is trial 41 with value: 0.14873681733257096.\n","output_type":"stream"},{"name":"stdout","text":"최적 RMSLE: 0.14873681733257096\n최적 가중치: [0.8465243289562155, 0.1534756710437845]\n","output_type":"stream"}]},{"cell_type":"code","source":"# 앙상블 모델 설정\nestimators = [\n    ('lgbm', LGBMRegressor(**lgb_params)),\n    ('catboost', CatBoostRegressor(**cat_params, silent=True))\n]\n\n# VotingRegressor 초기화\nvoting_regressor = VotingRegressor(estimators=estimators, weights=best_weights)  # 가중치\n\ntest_predictions = np.zeros(X_test.shape[0])\ncv_scores = []\n\n# KFold를 사용하여 교차 검증을 수행\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (train_indices, valid_indices) in enumerate(kf.split(X_train, y_train)):\n    print(f\"Fold {fold+1}의 모델 훈련\")\n    X_train_fold, X_valid_fold = X_train.iloc[train_indices], X_train.iloc[valid_indices]\n    y_train_fold, y_valid_fold = np.log1p(y_train.iloc[train_indices]), np.log1p(y_train.iloc[valid_indices])\n\n    # 모델 훈련\n    voting_regressor.fit(X_train_fold, y_train_fold)\n\n    # 검증 데이터에 대한 예측 및 RMSLE 점수 계산\n    valid_pred = voting_regressor.predict(X_valid_fold)\n    valid_pred = np.expm1(valid_pred)  # 예측값을 원래 척도로 변환\n    cv_score = rmsle(np.expm1(y_valid_fold), valid_pred)  # y_valid_fold를 원래 척도로 변환\n    cv_scores.append(cv_score)\n    print(f\"Fold {fold+1}의 RMSLE: {cv_score}\")\n\n    # 테스트 데이터에 대한 예측\n    test_pred = np.expm1(voting_regressor.predict(X_test))\n    test_predictions += test_pred / kf.n_splits\n\n# 폴드별 RMSLE 점수의 평균 표시\nprint()\nprint(f\"폴드별 평균 RMSLE: {np.mean(cv_scores)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIoueezUGClB","outputId":"d1142cc8-f439-4b8b-aae9-535cd2b8201f","execution":{"iopub.status.busy":"2024-04-24T03:09:06.049481Z","iopub.execute_input":"2024-04-24T03:09:06.049870Z","iopub.status.idle":"2024-04-24T03:11:16.234074Z","shell.execute_reply.started":"2024-04-24T03:09:06.049837Z","shell.execute_reply":"2024-04-24T03:11:16.233144Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Fold 1의 모델 훈련\nFold 1의 RMSLE: 0.14902184229785004\nFold 2의 모델 훈련\nFold 2의 RMSLE: 0.1500184843459772\nFold 3의 모델 훈련\nFold 3의 RMSLE: 0.14873790359143657\nFold 4의 모델 훈련\nFold 4의 RMSLE: 0.14778182053560424\nFold 5의 모델 훈련\nFold 5의 RMSLE: 0.14812403589198675\n\n폴드별 평균 RMSLE: 0.14873681733257096\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create submission file\nsample_df['Rings'] = test_predictions\nsample_df.to_csv('submission.csv', index=False)\nsample_df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"a8jpv5-GHo31","outputId":"9fd09a50-cee4-4b40-a271-c2d7e4d94ebe","execution":{"iopub.status.busy":"2024-04-24T03:11:16.235451Z","iopub.execute_input":"2024-04-24T03:11:16.236377Z","iopub.status.idle":"2024-04-24T03:11:16.453501Z","shell.execute_reply.started":"2024-04-24T03:11:16.236342Z","shell.execute_reply":"2024-04-24T03:11:16.452137Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"           id      Rings\n0       90615   9.589754\n1       90616   9.699243\n2       90617   9.809732\n3       90618  10.596506\n4       90619   7.554818\n...       ...        ...\n60406  151021   6.237972\n60407  151022   9.496125\n60408  151023  12.253507\n60409  151024  13.229788\n60410  151025   8.290916\n\n[60411 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Rings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>90615</td>\n      <td>9.589754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90616</td>\n      <td>9.699243</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>90617</td>\n      <td>9.809732</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>90618</td>\n      <td>10.596506</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90619</td>\n      <td>7.554818</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60406</th>\n      <td>151021</td>\n      <td>6.237972</td>\n    </tr>\n    <tr>\n      <th>60407</th>\n      <td>151022</td>\n      <td>9.496125</td>\n    </tr>\n    <tr>\n      <th>60408</th>\n      <td>151023</td>\n      <td>12.253507</td>\n    </tr>\n    <tr>\n      <th>60409</th>\n      <td>151024</td>\n      <td>13.229788</td>\n    </tr>\n    <tr>\n      <th>60410</th>\n      <td>151025</td>\n      <td>8.290916</td>\n    </tr>\n  </tbody>\n</table>\n<p>60411 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}